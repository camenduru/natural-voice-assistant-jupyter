{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/natural-voice-assistant-jupyter/blob/main/natural_voice_assistant_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone --recursive -b dev https://github.com/camenduru/natural_voice_assistant\n",
        "%cd /content/natural_voice_assistant\n",
        "\n",
        "!apt install -qq espeak-ng portaudio19-dev\n",
        "!pip install -q pyaudio sounddevice wget omegaconf pytorch_lightning phonemizer munch einops_exts accelerate pyngrok\n",
        "!pip install -q git+https://github.com/resemble-ai/monotonic_align\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().auth_token = 'NGROK_TOKEN_HERE'\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/natural_voice_assistant\n",
        "\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import pyaudio\n",
        "import multiprocessing\n",
        "import sounddevice as sd\n",
        "from utils_voice_assistant.preprocessor import Preprocessor\n",
        "from utils_voice_assistant.streaming_buffer import StreamBuffer\n",
        "from models_voice_assistant.stt_llm_tts_model import STT_LLM_TTS\n",
        "\n",
        "import threading\n",
        "\n",
        "from flask import Flask, render_template, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "prev_response = None\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/test')\n",
        "def get_counter():\n",
        "    if prev_response is not None:\n",
        "        print( prev_response.id, prev_response.input)\n",
        "        return jsonify(id = prev_response.id, input=prev_response.input, response = prev_response.response)\n",
        "    else:\n",
        "        return jsonify(id = -1, input=\"\", response=\"\")\n",
        "\n",
        "def start_ui():\n",
        "    app.run(debug=True, use_reloader=False, port=5000)\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(0.1)  # Your main thread can continue doing other things\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Main thread interrupted and exiting...\")\n",
        "\n",
        "\n",
        "\n",
        "def record(audio_buffer, start_recording):\n",
        "    \"\"\"Record an audio stream from the microphone in a separate process  \n",
        "        Args:\n",
        "            audio_buffer: multiprocessing queue to store the recorded audio data\n",
        "            start_recording: multiprocessing value to start and stop the recording\n",
        "    \"\"\"\n",
        "    RATE = 16000\n",
        "    CHUNK = 2048\n",
        "\n",
        "    # Open audio input stream\n",
        "    audio = pyaudio.PyAudio()\n",
        "    streamIn = audio.open(format=pyaudio.paFloat32, channels=1,\n",
        "                            rate=RATE, input=True, input_device_index=0,\n",
        "                            frames_per_buffer=CHUNK)\n",
        "    \n",
        "    while(True):\n",
        "        try:\n",
        "            # start_recording is set to 1 in the main loop to start the recording\n",
        "            if start_recording == 0:\n",
        "                time.sleep(0.1)\n",
        "                continue\n",
        "            # read a chunk of fixed size from the input stream and add it to the input buffer \n",
        "            data = streamIn.read(CHUNK, exception_on_overflow=False)\n",
        "            audio_buffer.put(data)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            return\n",
        "        \n",
        "        except Exception as e:\n",
        "            raise e \n",
        "        \n",
        "def play_audio(audio_output_buffer):\n",
        "    \"\"\"Play synthesized audio data in a separate process  \n",
        "        Args:\n",
        "            audio_output_buffer: multiprocessing-queue to receive audio data\n",
        "    \"\"\"\n",
        "    fs = 24000\n",
        "    while(True):\n",
        "        # get next audio data \n",
        "        wav = audio_output_buffer.get()\n",
        "        # play the audio and wait until it is finished (only this sub process is blocked, not the main loop)\n",
        "        sd.play(wav, fs, blocking=True) \n",
        "\n",
        "def flush():\n",
        "  \"\"\"Flush Cuda cache to prevent side effect and slowdowns   \n",
        "  \"\"\"\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "def main_loop(streaming_buffer, model, audio_input_buffer, audio_output_buffer,  start_recording):\n",
        "    \"\"\"Wait for audio input, call voice assistant model and play synthesized speech  \n",
        "        Args:\n",
        "            streaming_buffer: streaming buffer instance to store preprocessed audio chunks\n",
        "            model: instance of STT_LLM_TTS model\n",
        "            audio_input_buffer: multiprocessing queue for audio input\n",
        "            audio_output_buffer: multiprocessing queue for audio output\n",
        "            start_recording: multiprocessing value to start recording of audio chunks\n",
        "    \"\"\"\n",
        "    # init preprocessor and streaming iterator\n",
        "    preprocessor = Preprocessor()\n",
        "    streaming_buffer_iter = iter(streaming_buffer)\n",
        "    \n",
        "    # send signal to recording process to start the recording\n",
        "    start_recording.value = 1\n",
        "\n",
        "    # control buffer stream id for first chunk \n",
        "    first_chunk = True\n",
        "    first_response = True\n",
        "\n",
        "    # start main loop\n",
        "    while True:\n",
        "\n",
        "        # get as many audio chunks from the buffer as possible. If the buffer is empty, an exception is thrown \n",
        "        # and the inner loop breaks\n",
        "        while True:\n",
        "            # select stream id (-1) for first chunk (0) else\n",
        "            if first_chunk:\n",
        "                stream_id = -1\n",
        "                first_chunk = False\n",
        "            else:\n",
        "                stream_id = 0\n",
        "\n",
        "            # try to get the next audio chunk, if buffer is empty an exception is thrown \n",
        "            try:\n",
        "                # get audio data from buffer\n",
        "                data = audio_input_buffer.get(block=False)\n",
        "                \n",
        "                # preprocess audio data\n",
        "                t = torch.frombuffer(data, dtype=torch.float32)\n",
        "                t = torch.unsqueeze(t,0)\n",
        "                length = torch.tensor([t.shape[1]], dtype=torch.float32)\n",
        "                processed_signal, _ = preprocessor(t, length)\n",
        "\n",
        "                # add processed audio chunks to the streaming buffer \n",
        "                streaming_buffer.append_processed_signal(processed_signal, stream_id=stream_id)\n",
        "            except Exception as e:\n",
        "                # leave inner loop and process received data\n",
        "                break\n",
        "                \n",
        "        # check if enough audio chunks were recorded for a forward path\n",
        "        if streaming_buffer.buffer is not None and streaming_buffer.buffer.size(-1) > streaming_buffer.buffer_idx + streaming_buffer.shift_size:\n",
        "            # --> enough chunks are available \n",
        "\n",
        "            # get preprocessed audio chunks from buffer\n",
        "            data = next(streaming_buffer_iter, None)\n",
        "            if data is None: \n",
        "                break\n",
        "            chunk_audio, chunk_lengths = data\n",
        "            \n",
        "            # call model and pass preprocessed audio data\n",
        "            chunk_audio = chunk_audio.to(\"cuda\")\n",
        "            chunk_lengths = chunk_lengths.to(\"cuda\")\n",
        "            response = model(chunk_audio, chunk_lengths) \n",
        "        else:\n",
        "            # --> not enough chunks. Call model with empty input to generate text\n",
        "            response = model(None, None)\n",
        "\n",
        "        if first_response:\n",
        "            streaming_buffer.reset_buffer()\n",
        "            first_response = False\n",
        "            first_chunk = True\n",
        "\n",
        "        # print(\"INPUT: \", response.input)\n",
        "        # print(\"OUTPUT: \", response.response.replace(\"\\n\", \"\"))\n",
        "        global prev_response\n",
        "        prev_response = response\n",
        "\n",
        "\n",
        "        # TODO: Implement interrup behavior to stop audio process when user starts speaking\n",
        "\n",
        "        # model return is None except when a new sentence is generated and synthesized \n",
        "        if response.finished:\n",
        "            # --> A new sentence is finished\n",
        "            # print(\"INPUT: \", response.input)\n",
        "            # print(\"OUTPUT: \", response.response.replace(\"\\n\", \"\"))\n",
        "\n",
        "            # Put synthesized audio to output buffer which will be played by the play-audio process\n",
        "            audio_output_buffer.put(response.speech)\n",
        "        \n",
        "        time.sleep(0.001) # TODO Is this really needed?\n",
        "                \n",
        "def main():\n",
        "    \"\"\" Start processes for recording and audio output, initialize voice assist model and start main loop \n",
        "    \"\"\"\n",
        "    # !! Make sure to start multiprocessing before using any pytorch tensors to prevent GPU memory problems !! \n",
        "\n",
        "    #start_ui()\n",
        "    ui_thread = threading.Thread(target=start_ui, daemon=True)\n",
        "    ui_thread.start()\n",
        "\n",
        "    # start multiprocesses for sound input\n",
        "    audio_buffer = multiprocessing.Queue() \n",
        "    start_recording = multiprocessing.Value('i', 0)\n",
        "    record_process = multiprocessing.Process(target=record, args=(audio_buffer,start_recording))\n",
        "    record_process.start()\n",
        "\n",
        "    # start multiprocesses for sound output\n",
        "    audio_output_buffer = multiprocessing.Queue()\n",
        "    play_audio_process = multiprocessing.Process(target=play_audio, args=(audio_output_buffer,))\n",
        "    play_audio_process.start()\n",
        "\n",
        "    \n",
        "\n",
        "    # initialize buffer for processed audio input\n",
        "    streaming_buffer = StreamBuffer(chunk_size=16, shift_size=16)\n",
        "\n",
        "    # get device\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda'\n",
        "        # flush GPU memory\n",
        "        flush()\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "        \n",
        "    # init STT-LLM-TTS pipeline\n",
        "    model = STT_LLM_TTS(device=device)\n",
        "\n",
        "    # start inference\n",
        "    main_loop(streaming_buffer, model, audio_buffer, audio_output_buffer,  start_recording)\n",
        "   \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
